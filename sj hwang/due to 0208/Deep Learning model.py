# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

# GPU ì‚¬ìš© ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ–¥ Using device: {device}")

# í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
# í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ìµœì í™”)
def evaluate_model(y_true, y_pred, model_name):
    try:
        # ğŸ”¹ 1D ë°°ì—´ë¡œ ë³€í™˜ (2D ë˜ëŠ” ë‹¤ë¥¸ ì°¨ì› ë°©ì§€)
        y_true = np.array(y_true).reshape(-1).astype(np.float32)
        y_pred = np.array(y_pred).reshape(-1).astype(np.float32)

        # ğŸ”¹ í¬ê¸° ë§ì¶”ê¸° (ì˜ˆì¸¡ê°’ì´ ë” ë§ì„ ê²½ìš° ìë¥´ê¸°)
        min_length = min(len(y_true), len(y_pred))
        y_true, y_pred = y_true[:min_length], y_pred[:min_length]

        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100  # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë¬¸ì œ ë°©ì§€

        print(f"ğŸ“Š {model_name} í‰ê°€ ê²°ê³¼:")
        print(f"âœ… MSE  (Mean Squared Error): {mse:.4f}")
        print(f"âœ… RMSE (Root Mean Squared Error): {rmse:.4f}")
        print(f"âœ… MAE  (Mean Absolute Error): {mae:.4f}")
        print(f"âœ… MAPE (Mean Absolute Percentage Error): {mape:.2f}%\n")

        return mse, rmse, mae, mape

    except Exception as e:
        print(f"ğŸš¨ {model_name}: í‰ê°€ ì˜¤ë¥˜ ë°œìƒ - {e}")
        return None


# ë°ì´í„°ì…‹ í´ë˜ìŠ¤
class TimeSeriesDataset(Dataset):
    def __init__(self, data, target, seq_length=10):
        self.data = data
        self.target = target
        self.seq_length = seq_length

    def __len__(self):
        return len(self.data) - self.seq_length

    def __getitem__(self, idx):
        x = self.data[idx:idx+self.seq_length]
        y = self.target[idx+self.seq_length]
        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)

# ëª¨ë¸ ì •ì˜
class RNNModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(RNNModel, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = x.contiguous()  # ğŸ”¹ ë¹„ì—°ì†ì ì¸ í…ì„œë¥¼ ì—°ì†ì ì¸ í…ì„œë¡œ ë³€í™˜
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return self.sigmoid(out)


class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = x.contiguous()
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return self.sigmoid(out)

class GRUModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(GRUModel, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = x.contiguous()
        out, _ = self.gru(x)
        out = self.fc(out[:, -1, :])
        return self.sigmoid(out)



class TransformerModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=2, num_heads=2):
        super(TransformerModel, self).__init__()
        self.encoder = nn.Linear(input_size, hidden_size)
        self.transformer = nn.Transformer(hidden_size, num_heads, num_layers)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.encoder(x)
        x = self.transformer(x, x)
        x = self.fc(x[:, -1, :])
        return x

# í•™ìŠµ í•¨ìˆ˜
def train_model(model, train_loader, criterion, optimizer, num_epochs=20):
    model.to(device)
    loss_history = []
    for epoch in range(num_epochs):
        for x_batch, y_batch in train_loader:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            outputs = model(x_batch)
            loss = criterion(outputs, y_batch.unsqueeze(1))
            loss.backward()
            optimizer.step()
        loss_history.append(loss.item())
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")
    return loss_history

# ì‹œê°í™” í•¨ìˆ˜
def plot_loss(loss_history, model_name, method):
    plt.figure(figsize=(10,5))
    plt.plot(loss_history, label="Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title(f"{model_name}_{method} Training Loss")
    plt.legend()
    plt.show()

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def train_and_evaluate_dl_models(train_path, test_path, method):
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘... ({method})")
    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)

    # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ + NaN ì œê±°
    num_features = train_df.select_dtypes(include=[np.number]).dropna()

    if num_features.shape[1] == 0:
        print(f"ğŸš¨ {method}: ë³€í™˜í•  ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŒ! ë°ì´í„° í™•ì¸ í•„ìš”.")
        print("í˜„ì¬ ë°ì´í„° íƒ€ì…:\n", train_df.dtypes)
        print("í˜„ì¬ ë°ì´í„° ìƒ˜í”Œ:\n", train_df.head())
        return

    # MinMaxScaler ì ìš©
    scaler = MinMaxScaler()
    X_train = scaler.fit_transform(num_features.drop(columns=["ì„ì‹  ì„±ê³µ ì—¬ë¶€"], errors="ignore"))

    # NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
    if np.isnan(X_train).sum() > 0:
        print(f"ğŸš¨ {method}: MinMaxScaler ë³€í™˜ í›„ì—ë„ NaN ê°’ ì¡´ì¬! â†’ ì œê±° ì§„í–‰")
        X_train = np.nan_to_num(X_train)

    # ë³€í™˜ëœ ë°ì´í„° í™•ì¸
    print(f"âœ… {method} ë³€í™˜ëœ X_train ê°’ í™•ì¸: Min={np.min(X_train)}, Max={np.max(X_train)}")

    y_train = num_features["ì„ì‹  ì„±ê³µ ì—¬ë¶€"].values

    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    dataset = TimeSeriesDataset(X_train, y_train)
    train_loader = DataLoader(dataset, batch_size=64, shuffle=True)

    # ëª¨ë¸ë“¤ ì •ì˜
    models = {
        "RNN": RNNModel(input_size=X_train.shape[1], hidden_size=64, output_size=1),
        "LSTM": LSTMModel(input_size=X_train.shape[1], hidden_size=64, output_size=1),
        "GRU": GRUModel(input_size=X_train.shape[1], hidden_size=64, output_size=1),
        "Transformer": TransformerModel(input_size=X_train.shape[1], hidden_size=64, output_size=1)
    }

    # ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²•
    criterion = nn.MSELoss()
    optimizers = {name: optim.Adam(model.parameters(), lr=0.001) for name, model in models.items()}

    # ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    for model_name, model in models.items():
        print(f"ğŸš€ {model_name} ëª¨ë¸ í•™ìŠµ ì‹œì‘... ({method})")
        loss_history = train_model(model, train_loader, criterion, optimizers[model_name])
        plot_loss(loss_history, model_name, method)

        # âœ… ì˜ˆì¸¡ ìˆ˜í–‰ (ì—°ì†ì ì¸ í…ì„œ ë³€í™˜ ì¶”ê°€)
        X_test_tensor = torch.tensor(X_train[-len(test_df):], dtype=torch.float32).to(device).contiguous()
        X_test_tensor = X_test_tensor.view(X_test_tensor.shape[0], 1, -1)  # ğŸ”¹ RNN ì…ë ¥ í˜•íƒœ ë³€í™˜

        y_pred = model(X_test_tensor).cpu().detach().numpy()

        # í‰ê°€ ë° ê²°ê³¼ ì €ì¥
        evaluate_model(y_train[-len(y_pred):], y_pred, f"{model_name}_{method}")
        output_dir = "./DeepLearning_result"
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"{output_dir}/{model_name}_{method}_sample.csv"
        pd.DataFrame({"ID": test_df["ID"], "probability": y_pred.flatten()}).to_csv(output_filename, index=False)
        print(f"âœ… {model_name} ê²°ê³¼ ì €ì¥ ì™„ë£Œ! ({output_filename})")

# ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    methods = ["linear", "poly", "mean", "knn"]
    for method in methods:
        train_and_evaluate_dl_models(f"./preprocessing/train_{method}.csv", f"./preprocessing/test_{method}.csv", method)
