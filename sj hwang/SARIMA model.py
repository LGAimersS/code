# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_squared_error, mean_absolute_error
from pmdarima import auto_arima  # ìµœì ì˜ (p, d, q) íƒìƒ‰
import warnings
import os

# FutureWarning ë¬´ì‹œ
warnings.filterwarnings("ignore", category=FutureWarning)

# í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
def evaluate_model(y_true, y_pred, model_name):
    if len(y_true) == 0 or len(y_pred) == 0:
        print(f"ğŸš¨ {model_name}: í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŒ")
        return None

    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    print(f"ğŸ“Š {model_name} í‰ê°€ ê²°ê³¼:")
    print(f"âœ… MSE  (Mean Squared Error): {mse:.4f}")
    print(f"âœ… RMSE (Root Mean Squared Error): {rmse:.4f}")
    print(f"âœ… MAE  (Mean Absolute Error): {mae:.4f}")
    print(f"âœ… MAPE (Mean Absolute Percentage Error): {mape:.2f}%\n")

    return mse, rmse, mae, mape

# ì‹œê°í™” í•¨ìˆ˜ (ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ë¹„êµ)
def plot_predictions(y_true, y_pred, model_name):
    if len(y_true) == 0 or len(y_pred) == 0:
        print(f"ğŸš¨ {model_name}: ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•¨")
        return

    plt.figure(figsize=(12, 6))
    plt.plot(y_true.values, label="Actual", color="blue")
    plt.plot(y_pred, label="Predicted", color="red")  # ì¼ë°˜ ì„  ê·¸ë˜í”„
    plt.legend()
    plt.title(f"{model_name} Predictions vs Actual")
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.show()

# ì”ì°¨ ë¶„ì„ (Residual Plot)
def plot_residuals(y_true, y_pred, model_name):
    if len(y_true) == 0 or len(y_pred) == 0:
        print(f"ğŸš¨ {model_name}: ì”ì°¨ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•¨")
        return

    residuals = y_true - y_pred
    plt.figure(figsize=(12, 6))
    sns.histplot(residuals, kde=True, bins=30)
    plt.title(f"{model_name} Residual Distribution")
    plt.xlabel("Residuals")
    plt.ylabel("Frequency")
    plt.show()

# SARIMA ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ í•¨ìˆ˜
def train_and_evaluate_sarima(train_path, test_path, method):
    try:
        # 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
        print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘... ({method})")
        train_df = pd.read_csv(train_path)
        test_df = pd.read_csv(test_path)

        # 2ï¸âƒ£ í•™ìŠµ ë°ì´í„°ì—ì„œ 'ì„ì‹  ì„±ê³µ ì—¬ë¶€' ê°€ì ¸ì˜¤ê¸°
        if "ì„ì‹  ì„±ê³µ ì—¬ë¶€" not in train_df.columns:
            print(f"ğŸš¨ {method}: 'ì„ì‹  ì„±ê³µ ì—¬ë¶€' ì»¬ëŸ¼ì´ ì—†ìŒ")
            return

        y_train = train_df["ì„ì‹  ì„±ê³µ ì—¬ë¶€"]

        # 3ï¸âƒ£ NaN ê°’ ì œê±° (í•„ìˆ˜)
        y_train = y_train.dropna()

        # 4ï¸âƒ£ ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if len(y_train) == 0:
            print(f"ğŸš¨ {method}: í›ˆë ¨ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŒ â†’ ëª¨ë¸ í•™ìŠµ ê±´ë„ˆëœ€")
            return

        # 5ï¸âƒ£ ìµœì ì˜ SARIMA íŒŒë¼ë¯¸í„° ì°¾ê¸° (auto_arima ì‚¬ìš©)
        print(f"ğŸ” ìµœì ì˜ SARIMA íŒŒë¼ë¯¸í„° ì°¾ëŠ” ì¤‘... ({method})")
        optimal_sarima = auto_arima(y_train, seasonal=True, m=12, trace=True)
        best_order = optimal_sarima.order
        best_seasonal_order = optimal_sarima.seasonal_order
        print(f"âœ… ìµœì ì˜ SARIMA íŒŒë¼ë¯¸í„°: {best_order}, ê³„ì ˆì„±: {best_seasonal_order}")

        # 6ï¸âƒ£ SARIMA ëª¨ë¸ í›ˆë ¨
        print(f"ğŸš€ SARIMA ëª¨ë¸ í•™ìŠµ ì‹œì‘... ({method})")
        model = SARIMAX(y_train, order=best_order, seasonal_order=best_seasonal_order)
        model_fit = model.fit()

        # 7ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
        print(f"ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘... ({method})")
        y_pred = model_fit.forecast(steps=len(test_df))
        y_pred = np.nan_to_num(y_pred)  # NaNì´ ë‚˜ì˜¤ë©´ 0ìœ¼ë¡œ ëŒ€ì²´

        # 8ï¸âƒ£ í‰ê°€ ì§€í‘œ ì¶œë ¥
        evaluate_model(y_train[-len(y_pred):], y_pred, f"SARIMA_{method}")

        # 9ï¸âƒ£ ì‹œê°í™” (ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ë¹„êµ)
        plot_predictions(y_train[-len(y_pred):], y_pred, f"SARIMA_{method}")
        plot_residuals(y_train[-len(y_pred):], y_pred, f"SARIMA_{method}")

        # ğŸ”Ÿ ì›ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì™€ ë³‘í•©í•˜ì—¬ ëª¨ë“  ID í¬í•¨
        original_test_df = pd.read_csv("./datasets/test.csv")[["ID"]]
        sarima_results = pd.DataFrame({"ID": test_df["ID"], "probability": y_pred})

        final_submission = original_test_df.merge(sarima_results, on="ID", how="left")
        final_submission["probability"] = final_submission["probability"].fillna(0)

        # 1ï¸âƒ£1ï¸âƒ£ ê²°ê³¼ ì €ì¥
        output_dir = "./Sarima_result"
        os.makedirs(output_dir, exist_ok=True)  # ë””ë ‰í„°ë¦¬ ìë™ ìƒì„±
        output_filename = f"{output_dir}/SARIMA_{method}_sample.csv"
        final_submission.to_csv(output_filename, index=False)
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! ({output_filename})")

    except Exception as e:
        print(f"ğŸš¨ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ğŸ”¥ ì‹¤í–‰ ì½”ë“œ (5ê°€ì§€ ì „ì²˜ë¦¬ ë°©ì‹ë³„ í•™ìŠµ)
if __name__ == "__main__":
    methods = ["remove", "linear", "poly", "mean", "knn"]
    train_files = {m: f"./preprocessing/train_{m}.csv" for m in methods}
    test_files = {m: f"./preprocessing/test_{m}.csv" for m in methods}

    for method in methods:
        train_and_evaluate_sarima(train_files[method], test_files[method], method)
